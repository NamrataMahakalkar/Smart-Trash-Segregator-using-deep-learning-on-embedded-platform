{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPEKMiMRKc9sUfjXcSdr3Hg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"TMRGSLHwRio_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1594001835997,"user_tz":-330,"elapsed":53500,"user":{"displayName":"namrata mahakalkar","photoUrl":"","userId":"00881903954940034536"}},"outputId":"aef44bd6-f1f7-412b-8adf-7b7b587813ae"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JVC040WcS5Qz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1594001946653,"user_tz":-330,"elapsed":7611,"user":{"displayName":"namrata mahakalkar","photoUrl":"","userId":"00881903954940034536"}},"outputId":"bc8d78ab-243b-489e-f8e8-2af593156d77"},"source":["!pip3 install https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.2/imageai-2.0.2-py3-none-any.whl"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting imageai==2.0.2\n","\u001b[?25l  Downloading https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.2/imageai-2.0.2-py3-none-any.whl (151kB)\n","\u001b[K     |████████████████████████████████| 153kB 380kB/s \n","\u001b[?25hInstalling collected packages: imageai\n","Successfully installed imageai-2.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DHFYuZ6sTA4g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":683},"executionInfo":{"status":"ok","timestamp":1594002016890,"user_tz":-330,"elapsed":68920,"user":{"displayName":"namrata mahakalkar","photoUrl":"","userId":"00881903954940034536"}},"outputId":"f14b43a7-b0a5-4e58-90c1-494318ce8134"},"source":["pip install tensorflow-gpu==1.13.1"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu==1.13.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n","\u001b[K     |████████████████████████████████| 345.2MB 52kB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.30.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.2)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.9.0)\n","Collecting tensorboard<1.14.0,>=1.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 35.1MB/s \n","\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n","Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n","\u001b[K     |████████████████████████████████| 368kB 40.7MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.10.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.3.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.18.5)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.34.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.12.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.0.8)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.2.2)\n","Collecting mock>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (47.3.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.6.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.1.0)\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.13.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 1.13.0 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboard, mock, tensorflow-estimator, tensorflow-gpu\n","  Found existing installation: tensorboard 2.2.2\n","    Uninstalling tensorboard-2.2.2:\n","      Successfully uninstalled tensorboard-2.2.2\n","  Found existing installation: tensorflow-estimator 2.2.0\n","    Uninstalling tensorflow-estimator-2.2.0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0\n","Successfully installed mock-4.0.2 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pWpeUJo9TXPx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594002068072,"user_tz":-330,"elapsed":4377,"user":{"displayName":"namrata mahakalkar","photoUrl":"","userId":"00881903954940034536"}},"outputId":"b4bab2e0-0cbb-4575-c07d-c3a3a279c0b6"},"source":["!python3 --version"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Python 3.6.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4YTiL_frTb6B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":343},"executionInfo":{"status":"ok","timestamp":1594002076130,"user_tz":-330,"elapsed":6277,"user":{"displayName":"namrata mahakalkar","photoUrl":"","userId":"00881903954940034536"}},"outputId":"29556c42-aee9-463d-b729-140edca16d41"},"source":["pip install imageai --upgrade"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting imageai\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/99/4023e191a343fb23f01ae02ac57a5ca58037c310e8d8c62f87638a3bafc7/imageai-2.1.5-py3-none-any.whl (180kB)\n","\r\u001b[K     |█▉                              | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 30kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 40kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 61kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 71kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 81kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 92kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 102kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 112kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 122kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 133kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 143kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 153kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 163kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 174kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 7.0MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from imageai) (3.2.2)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from imageai) (2.10.0)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from imageai) (1.4.1)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from imageai) (1.18.5)\n","Requirement already satisfied, skipping upgrade: pillow in /usr/local/lib/python3.6/dist-packages (from imageai) (7.0.0)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (1.2.0)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (0.10.0)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (2.4.7)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (2.8.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py->imageai) (1.12.0)\n","Installing collected packages: imageai\n","  Found existing installation: imageai 2.0.2\n","    Uninstalling imageai-2.0.2:\n","      Successfully uninstalled imageai-2.0.2\n","Successfully installed imageai-2.1.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3nhmGDq8m3Qf","colab_type":"text"},"source":["change runtime and make 15 experiment before running the training code."]},{"cell_type":"code","metadata":{"id":"T3j73OY6TidO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"27334e9a-9fd3-44ae-af6a-09cbc1cc1734"},"source":["from imageai.Detection.Custom import DetectionModelTrainer\n","\n","trainer = DetectionModelTrainer()\n","trainer.setModelTypeAsYOLOv3()\n","trainer.setDataDirectory(data_directory=\"/content/drive/My Drive/ImageAI_0bj_det/dataset\")\n","trainer.setTrainConfig(object_names_array=[\"paper\", \"plastic\", \"metal\", \"cardboard\", \"glass\"], batch_size=4, num_experiments=50, train_from_pretrained_model=\"/content/drive/My Drive/ImageAI_0bj_det/pretrained-yolov3.h5\")\n","trainer.trainModel()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"stream","text":["Generating anchor boxes for training images and annotation...\n","Average IOU for 9 anchors: 0.80\n","Anchor Boxes generated.\n","Detection configuration saved in  /content/drive/My Drive/ImageAI_0bj_det/dataset/json/detection_config.json\n","Training on: \t['cardboard', 'glass', 'metal', 'paper', 'plastic']\n","Training with Batch Size:  4\n","Number of Experiments:  50\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/imageai/Detection/Custom/yolo.py:24: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Training with transfer learning from pretrained Model\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n","  warnings.warn('`epsilon` argument is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/50\n","824/824 [==============================] - 867s 1s/step - loss: 24.0863 - yolo_layer_1_loss: 2.7250 - yolo_layer_2_loss: 8.7846 - yolo_layer_3_loss: 12.5768\n","Epoch 2/50\n","824/824 [==============================] - 777s 943ms/step - loss: 8.0984 - yolo_layer_1_loss: 1.1430 - yolo_layer_2_loss: 2.9150 - yolo_layer_3_loss: 4.0404\n","Epoch 3/50\n","824/824 [==============================] - 769s 934ms/step - loss: 6.8430 - yolo_layer_1_loss: 0.9152 - yolo_layer_2_loss: 2.3470 - yolo_layer_3_loss: 3.5808\n","Epoch 4/50\n","824/824 [==============================] - 773s 938ms/step - loss: 5.8984 - yolo_layer_1_loss: 0.8288 - yolo_layer_2_loss: 1.9912 - yolo_layer_3_loss: 3.0784\n","Epoch 5/50\n","824/824 [==============================] - 773s 938ms/step - loss: 5.4173 - yolo_layer_1_loss: 0.7780 - yolo_layer_2_loss: 1.8444 - yolo_layer_3_loss: 2.7949\n","Epoch 6/50\n","824/824 [==============================] - 774s 939ms/step - loss: 5.2774 - yolo_layer_1_loss: 0.7127 - yolo_layer_2_loss: 1.7359 - yolo_layer_3_loss: 2.8289\n","Epoch 7/50\n","824/824 [==============================] - 776s 942ms/step - loss: 4.7626 - yolo_layer_1_loss: 0.6264 - yolo_layer_2_loss: 1.5965 - yolo_layer_3_loss: 2.5398\n","Epoch 8/50\n","824/824 [==============================] - 772s 937ms/step - loss: 4.4120 - yolo_layer_1_loss: 0.5520 - yolo_layer_2_loss: 1.4390 - yolo_layer_3_loss: 2.4211\n","Epoch 9/50\n","824/824 [==============================] - 777s 943ms/step - loss: 4.3284 - yolo_layer_1_loss: 0.4927 - yolo_layer_2_loss: 1.4442 - yolo_layer_3_loss: 2.3915\n","Epoch 10/50\n","824/824 [==============================] - 768s 932ms/step - loss: 3.9523 - yolo_layer_1_loss: 0.5267 - yolo_layer_2_loss: 1.3225 - yolo_layer_3_loss: 2.1031\n","Epoch 11/50\n","824/824 [==============================] - 772s 937ms/step - loss: 3.8908 - yolo_layer_1_loss: 0.4940 - yolo_layer_2_loss: 1.2815 - yolo_layer_3_loss: 2.1152\n","Epoch 12/50\n","824/824 [==============================] - 774s 940ms/step - loss: 3.8596 - yolo_layer_1_loss: 0.4829 - yolo_layer_2_loss: 1.2906 - yolo_layer_3_loss: 2.0861\n","Epoch 13/50\n","824/824 [==============================] - 775s 941ms/step - loss: 3.8634 - yolo_layer_1_loss: 0.5107 - yolo_layer_2_loss: 1.3353 - yolo_layer_3_loss: 2.0173\n","Epoch 14/50\n","824/824 [==============================] - 769s 934ms/step - loss: 3.4850 - yolo_layer_1_loss: 0.3727 - yolo_layer_2_loss: 1.2639 - yolo_layer_3_loss: 1.8483\n","Epoch 15/50\n","824/824 [==============================] - 772s 937ms/step - loss: 3.2359 - yolo_layer_1_loss: 0.3375 - yolo_layer_2_loss: 1.1125 - yolo_layer_3_loss: 1.7859\n","Epoch 16/50\n","824/824 [==============================] - 781s 947ms/step - loss: 3.2757 - yolo_layer_1_loss: 0.3913 - yolo_layer_2_loss: 1.0553 - yolo_layer_3_loss: 1.8291\n","Epoch 17/50\n","824/824 [==============================] - 773s 938ms/step - loss: 3.3653 - yolo_layer_1_loss: 0.3534 - yolo_layer_2_loss: 1.1337 - yolo_layer_3_loss: 1.8782\n","Epoch 18/50\n","824/824 [==============================] - 778s 944ms/step - loss: 2.8954 - yolo_layer_1_loss: 0.3375 - yolo_layer_2_loss: 1.0313 - yolo_layer_3_loss: 1.5266\n","Epoch 19/50\n","824/824 [==============================] - 776s 942ms/step - loss: 2.4352 - yolo_layer_1_loss: 0.2188 - yolo_layer_2_loss: 0.8106 - yolo_layer_3_loss: 1.4059\n","Epoch 20/50\n","824/824 [==============================] - 774s 939ms/step - loss: 2.2903 - yolo_layer_1_loss: 0.2191 - yolo_layer_2_loss: 0.7899 - yolo_layer_3_loss: 1.2812\n","Epoch 21/50\n","824/824 [==============================] - 773s 938ms/step - loss: 2.2864 - yolo_layer_1_loss: 0.1781 - yolo_layer_2_loss: 0.7219 - yolo_layer_3_loss: 1.3865\n","Epoch 22/50\n","824/824 [==============================] - 772s 937ms/step - loss: 2.3664 - yolo_layer_1_loss: 0.2617 - yolo_layer_2_loss: 0.8197 - yolo_layer_3_loss: 1.2851\n","Epoch 23/50\n","824/824 [==============================] - 766s 930ms/step - loss: 2.0782 - yolo_layer_1_loss: 0.2067 - yolo_layer_2_loss: 0.6856 - yolo_layer_3_loss: 1.1859\n","Epoch 24/50\n","824/824 [==============================] - 770s 934ms/step - loss: 2.2075 - yolo_layer_1_loss: 0.2342 - yolo_layer_2_loss: 0.7159 - yolo_layer_3_loss: 1.2573\n","Epoch 25/50\n","824/824 [==============================] - 775s 941ms/step - loss: 2.1787 - yolo_layer_1_loss: 0.2496 - yolo_layer_2_loss: 0.7096 - yolo_layer_3_loss: 1.2195\n","Epoch 26/50\n","824/824 [==============================] - 774s 939ms/step - loss: 2.2245 - yolo_layer_1_loss: 0.2531 - yolo_layer_2_loss: 0.7351 - yolo_layer_3_loss: 1.2363\n","Epoch 27/50\n","824/824 [==============================] - 767s 931ms/step - loss: 2.0714 - yolo_layer_1_loss: 0.1671 - yolo_layer_2_loss: 0.7062 - yolo_layer_3_loss: 1.1981\n","Epoch 28/50\n","824/824 [==============================] - 782s 949ms/step - loss: 2.1186 - yolo_layer_1_loss: 0.2050 - yolo_layer_2_loss: 0.7043 - yolo_layer_3_loss: 1.2093\n","Epoch 29/50\n","824/824 [==============================] - 781s 948ms/step - loss: 2.0789 - yolo_layer_1_loss: 0.2076 - yolo_layer_2_loss: 0.6428 - yolo_layer_3_loss: 1.2285\n","Epoch 30/50\n","824/824 [==============================] - 772s 937ms/step - loss: 2.1312 - yolo_layer_1_loss: 0.2008 - yolo_layer_2_loss: 0.6761 - yolo_layer_3_loss: 1.2543\n","Epoch 31/50\n","824/824 [==============================] - 774s 940ms/step - loss: 2.0999 - yolo_layer_1_loss: 0.2116 - yolo_layer_2_loss: 0.7078 - yolo_layer_3_loss: 1.1805\n","Epoch 32/50\n","824/824 [==============================] - 779s 945ms/step - loss: 2.2316 - yolo_layer_1_loss: 0.2168 - yolo_layer_2_loss: 0.7651 - yolo_layer_3_loss: 1.2497\n","Epoch 33/50\n","824/824 [==============================] - 776s 941ms/step - loss: 2.2045 - yolo_layer_1_loss: 0.2109 - yolo_layer_2_loss: 0.7085 - yolo_layer_3_loss: 1.2851\n","Epoch 34/50\n","824/824 [==============================] - 787s 955ms/step - loss: 2.2650 - yolo_layer_1_loss: 0.2325 - yolo_layer_2_loss: 0.7902 - yolo_layer_3_loss: 1.2424\n","Epoch 35/50\n","824/824 [==============================] - 783s 950ms/step - loss: 2.1145 - yolo_layer_1_loss: 0.2186 - yolo_layer_2_loss: 0.6971 - yolo_layer_3_loss: 1.1988\n","Epoch 36/50\n","824/824 [==============================] - 775s 941ms/step - loss: 2.1338 - yolo_layer_1_loss: 0.2183 - yolo_layer_2_loss: 0.7382 - yolo_layer_3_loss: 1.1773\n","Epoch 37/50\n","824/824 [==============================] - 774s 940ms/step - loss: 2.2516 - yolo_layer_1_loss: 0.2146 - yolo_layer_2_loss: 0.7502 - yolo_layer_3_loss: 1.2867\n","Epoch 38/50\n","824/824 [==============================] - 770s 934ms/step - loss: 2.1439 - yolo_layer_1_loss: 0.2000 - yolo_layer_2_loss: 0.7353 - yolo_layer_3_loss: 1.2086\n","Epoch 39/50\n","824/824 [==============================] - 771s 936ms/step - loss: 2.3029 - yolo_layer_1_loss: 0.2556 - yolo_layer_2_loss: 0.7783 - yolo_layer_3_loss: 1.2690\n","Epoch 40/50\n","824/824 [==============================] - 769s 933ms/step - loss: 2.1598 - yolo_layer_1_loss: 0.2330 - yolo_layer_2_loss: 0.7012 - yolo_layer_3_loss: 1.2256\n","Epoch 41/50\n","824/824 [==============================] - 776s 941ms/step - loss: 2.1453 - yolo_layer_1_loss: 0.2619 - yolo_layer_2_loss: 0.7003 - yolo_layer_3_loss: 1.1831\n","Epoch 42/50\n","824/824 [==============================] - 768s 932ms/step - loss: 2.0407 - yolo_layer_1_loss: 0.1723 - yolo_layer_2_loss: 0.6958 - yolo_layer_3_loss: 1.1727\n","Epoch 43/50\n","824/824 [==============================] - 769s 933ms/step - loss: 2.1081 - yolo_layer_1_loss: 0.2098 - yolo_layer_2_loss: 0.7347 - yolo_layer_3_loss: 1.1636\n","Epoch 44/50\n","824/824 [==============================] - 768s 932ms/step - loss: 2.1494 - yolo_layer_1_loss: 0.2154 - yolo_layer_2_loss: 0.7313 - yolo_layer_3_loss: 1.2028\n","Epoch 45/50\n","824/824 [==============================] - 772s 937ms/step - loss: 2.1037 - yolo_layer_1_loss: 0.1848 - yolo_layer_2_loss: 0.7215 - yolo_layer_3_loss: 1.1974\n","Epoch 46/50\n","644/824 [======================>.......] - ETA: 2:49 - loss: 2.2405 - yolo_layer_1_loss: 0.2270 - yolo_layer_2_loss: 0.7253 - yolo_layer_3_loss: 1.2882"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qJ2sgqjxZERU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594009212851,"user_tz":-330,"elapsed":3308056,"user":{"displayName":"namrata mahakalkar","photoUrl":"","userId":"00881903954940034536"}},"outputId":"a8f382b7-f9e6-4274-adb5-ff74c7cb69d5"},"source":["from imageai.Detection.Custom import DetectionModelTrainer\n","\n","trainer = DetectionModelTrainer()\n","trainer.setModelTypeAsYOLOv3()\n","trainer.setDataDirectory(data_directory=\"/content/drive/My Drive/ImageAI_0bj_det/dataset\")\n","metrics = trainer.evaluateModel(model_path=\"/content/drive/My Drive/ImageAI_0bj_det/dataset/models\", json_path=\"/content/drive/My Drive/ImageAI_0bj_det/dataset/json/detection_config.json\", iou_threshold=0.5, object_threshold=0.3, nms_threshold=0.5)\n","print(metrics)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"stream","text":["Starting Model evaluation....\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/imageai/Detection/Custom/yolo.py:24: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n","  warnings.warn('No training configuration found in save file: '\n"],"name":"stderr"},{"output_type":"stream","text":["Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-001--loss-0020.657.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-001--loss-0021.709.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-001--loss-0024.086.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-002--loss-0008.098.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-002--loss-0008.247.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-002--loss-0009.405.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-003--loss-0006.843.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-003--loss-0007.240.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-004--loss-0005.898.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-004--loss-0005.979.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-005--loss-0005.417.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-005--loss-0005.655.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-006--loss-0005.277.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-006--loss-0005.366.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-007--loss-0004.763.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-007--loss-0004.873.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-008--loss-0004.412.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-008--loss-0004.552.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-009--loss-0004.328.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-009--loss-0004.339.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-010--loss-0003.952.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-010--loss-0004.310.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-011--loss-0003.891.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-011--loss-0004.073.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-012--loss-0003.700.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-012--loss-0003.860.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-014--loss-0003.485.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-014--loss-0003.698.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-015--loss-0003.066.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-015--loss-0003.236.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-016--loss-0002.639.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-017--loss-0002.561.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-018--loss-0002.435.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-018--loss-0002.895.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-019--loss-0002.435.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-020--loss-0002.290.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-020--loss-0002.362.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-021--loss-0002.286.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-023--loss-0002.078.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-023--loss-0002.200.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-025--loss-0002.130.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-026--loss-0002.082.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","Model File:  /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-027--loss-0002.071.h5 \n","\n","Using IoU :  0.5\n","Using Object Threshold :  0.3\n","Using Non-Maximum Suppression :  0.5\n","cardboard: 0.0000\n","glass: 0.0000\n","metal: 0.0000\n","paper: 0.0000\n","plastic: 0.0000\n","mAP: 0.0000\n","===============================\n","skipping the evaluation of /content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-042--loss-0002.041.h5 because following exception occurred: OOM when allocating tensor with shape[3,3,64,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n","\t [[node conv_7_44/random_uniform/RandomUniform (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4357) ]]\n","Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n","\n","\n","Caused by op 'conv_7_44/random_uniform/RandomUniform', defined at:\n","  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n","    \"__main__\", mod_spec)\n","  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n","    app.launch_new_instance()\n","  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n","    handler_func(fd_obj, events)\n","  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 456, in _handle_events\n","    self._handle_recv()\n","  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 486, in _handle_recv\n","    self._run_callback(callback, msg)\n","  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 438, in _run_callback\n","    callback(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n","    return self.dispatch_shell(stream, msg)\n","  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n","    handler(stream, idents, msg)\n","  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n","    user_expressions, allow_stdin)\n","  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n","    interactivity=interactivity, compiler=compiler, result=result)\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n","    if self.run_code(code, result):\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-6-a2558a751426>\", line 6, in <module>\n","    metrics = trainer.evaluateModel(model_path=\"/content/drive/My Drive/ImageAI_0bj_det/dataset/models\", json_path=\"/content/drive/My Drive/ImageAI_0bj_det/dataset/json/detection_config.json\", iou_threshold=0.5, object_threshold=0.3, nms_threshold=0.5)\n","  File \"/usr/local/lib/python3.6/dist-packages/imageai/Detection/Custom/__init__.py\", line 415, in evaluateModel\n","    infer_model = load_model(model_file)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\", line 492, in load_wrapper\n","    return load_function(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\", line 584, in load_model\n","    model = _deserialize_model(h5dict, custom_objects, compile)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\", line 274, in _deserialize_model\n","    model = model_from_config(model_config, custom_objects=custom_objects)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\", line 627, in model_from_config\n","    return deserialize(config, custom_objects=custom_objects)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\", line 168, in deserialize\n","    printable_module_name='layer')\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\", line 147, in deserialize_keras_object\n","    list(custom_objects.items())))\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\", line 1075, in from_config\n","    process_node(layer, node_data)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\", line 1025, in process_node\n","    layer(unpack_singleton(input_tensors), **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\", line 463, in __call__\n","    self.build(unpack_singleton(input_shapes))\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/convolutional.py\", line 141, in build\n","    constraint=self.kernel_constraint)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\", line 279, in add_weight\n","    weight = K.variable(initializer(shape, dtype=dtype),\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/initializers.py\", line 227, in __call__\n","    dtype=dtype, seed=self.seed)\n","  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 4357, in random_uniform\n","    shape, minval=minval, maxval=maxval, dtype=dtype, seed=seed)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\", line 4955, in random_uniform\n","    shape, minval=minval, maxval=maxval, dtype=dtype, seed=seed)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/random_ops.py\", line 247, in random_uniform\n","    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_random_ops.py\", line 777, in random_uniform\n","    name=name)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n","    op_def=op_def)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n","    op_def=op_def)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n","    self._traceback = tf_stack.extract_stack()\n","\n","ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,3,64,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n","\t [[node conv_7_44/random_uniform/RandomUniform (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4357) ]]\n","Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n","\n","\n","[{'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-001--loss-0020.657.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-001--loss-0021.709.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-001--loss-0024.086.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-002--loss-0008.098.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-002--loss-0008.247.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-002--loss-0009.405.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-003--loss-0006.843.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-003--loss-0007.240.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-004--loss-0005.898.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-004--loss-0005.979.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-005--loss-0005.417.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-005--loss-0005.655.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-006--loss-0005.277.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-006--loss-0005.366.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-007--loss-0004.763.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-007--loss-0004.873.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-008--loss-0004.412.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-008--loss-0004.552.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-009--loss-0004.328.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-009--loss-0004.339.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-010--loss-0003.952.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-010--loss-0004.310.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-011--loss-0003.891.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-011--loss-0004.073.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-012--loss-0003.700.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-012--loss-0003.860.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-014--loss-0003.485.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-014--loss-0003.698.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-015--loss-0003.066.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-015--loss-0003.236.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-016--loss-0002.639.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-017--loss-0002.561.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-018--loss-0002.435.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-018--loss-0002.895.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-019--loss-0002.435.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-020--loss-0002.290.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-020--loss-0002.362.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-021--loss-0002.286.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-023--loss-0002.078.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-023--loss-0002.200.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-025--loss-0002.130.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-026--loss-0002.082.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}, {'model_file': '/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-027--loss-0002.071.h5', 'using_iou': 0.5, 'using_object_threshold': 0.3, 'using_non_maximum_suppression': 0.5, 'average_precision': {'cardboard': 0, 'glass': 0, 'metal': 0, 'paper': 0, 'plastic': 0}, 'map': 0.0}]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Diyg_amcZJjY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":411},"executionInfo":{"status":"ok","timestamp":1593193318220,"user_tz":-330,"elapsed":37406,"user":{"displayName":"namrata mahakalkar","photoUrl":"","userId":"00881903954940034536"}},"outputId":"367363c5-036c-4292-db61-f213b0aa07ee"},"source":["from imageai.Detection.Custom import CustomObjectDetection\n","\n","detector = CustomObjectDetection()\n","detector.setModelTypeAsYOLOv3()\n","detector.setModelPath(\"/content/drive/My Drive/ImageAI_0bj_det/dataset/models/detection_model-ex-020--loss-0002.362.h5\")\n","detector.setJsonPath(\"/content/drive/My Drive/ImageAI_0bj_det/dataset/json/detection_config.json\")\n","detector.loadModel()\n","detections = detector.detectObjectsFromImage(input_image=\"/content/drive/My Drive/ImageAI_0bj_det/dataset/validation/images/trash411.JPG\", output_image_path=\"/content/drive/My Drive/ImageAI_0bj_det/dataset/trash411_detected.jpg\")\n","for detection in detections:\n","    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","cardboard  :  99.32531118392944  :  [46, 0, 720, 1896]\n","metal  :  99.61881637573242  :  [1652, 0, 2556, 806]\n","paper  :  99.77646470069885  :  [827, 77, 1460, 1141]\n","glass  :  99.1262137889862  :  [1021, 894, 1821, 1423]\n","glass  :  58.339279890060425  :  [1880, 1228, 2630, 1835]\n","metal  :  99.91671442985535  :  [1899, 1271, 2605, 1820]\n"],"name":"stdout"}]}]}